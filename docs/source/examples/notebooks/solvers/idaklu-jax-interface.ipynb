{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IDAKLU-Jax interface\n",
        "\n",
        "PyBaMM provides two mechanisms to interface battery models with JAX. The first (JaxSolver) implements PyBaMM models directly in native JAX, and as such provides the greatest flexibility. However, these models can be very slow to compile, especially during their initial run, and can require large amounts of memory.\n",
        "\n",
        "The second (the IDAKLU-Jax interface) instead provides a JAX-compliant interface to the IDAKLU solver. IDAKLU is a fast (compiled) solver based on SUNDIALS. By exposing the IDAKLU solver to JAX, we provide a fast solver capable of interfacing with third-party JAX-compatible software libraries, such as numpyro.\n",
        "\n",
        "Despite the apparent advantages, there are some limitations to this approach. The most notable is that model derivatives are limited to first-order (i.e. sensitivities), since the IDAKLU solver is not capable of auto-differentiation."
      ],
      "metadata": {
        "id": "GgclUjr3sT_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup a basic DFN model\n",
        "\n",
        "To demonstrate use of the IDAKLU-Jax interface, we first set-up a basic model, choosing the DFN model in this case. We will provide two `inputs` to the model and will specify a list of variables of interest (`output_variables`). Specifying `output_variables` is a requirement for use of the IDAKLU-Jax interface, though providing `inputs` is not."
      ],
      "metadata": {
        "id": "zsJLlejtzjcC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99tT6F73sRyc"
      },
      "outputs": [],
      "source": [
        "import pybamm\n",
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "inputs = {\n",
        "    \"Current function [A]\": 0.222,\n",
        "    \"Separator porosity\": 0.3,\n",
        "}\n",
        "\n",
        "model = pybamm.lithium_ion.DFN()\n",
        "geometry = model.default_geometry\n",
        "param = model.default_parameter_values\n",
        "param.update({key: \"[input]\" for key in inputs.keys()})\n",
        "param.process_geometry(geometry)\n",
        "param.process_model(model)\n",
        "var = pybamm.standard_spatial_vars\n",
        "var_pts = {var.x_n: 20, var.x_s: 20, var.x_p: 20, var.r_n: 10, var.r_p: 10}\n",
        "mesh = pybamm.Mesh(geometry, model.default_submesh_types, var_pts)\n",
        "disc = pybamm.Discretisation(mesh, model.default_spatial_methods)\n",
        "disc.process_model(model)\n",
        "t_eval = np.linspace(0, 360, 10)\n",
        "idaklu_solver = pybamm.IDAKLUSolver(rtol=1e-6, atol=1e-6)\n",
        "\n",
        "# Declare which variables to track\n",
        "output_variables = [\n",
        "    \"Terminal voltage [V]\",\n",
        "    \"Discharge capacity [A.h]\",\n",
        "    \"Loss of lithium inventory [%]\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We jaxify the IDAKLU solver in the same way that we would run any native IDAKLU solve. The only difference is that the `jaxify()` function returns an `IDAKLUJax` object, instead of a `Solution` object. We will keep track of this object, and can request a JAX-expression from it using the `get_jaxpr()` method, as below."
      ],
      "metadata": {
        "id": "QhMDaAjt0DR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is how we would normally create a Solve using IDAKLU\n",
        "sim = idaklu_solver.solve(\n",
        "    model,\n",
        "    t_eval,\n",
        "    inputs=inputs,\n",
        "    output_variables=output_variables,\n",
        "    calculate_sensitivities=True,\n",
        ")\n",
        "\n",
        "# Instead, we Jaxify the IDAKLU solver using the same arguments...\n",
        "jax_solver = idaklu_solver.jaxify(\n",
        "    model,\n",
        "    t_eval,\n",
        "    inputs=inputs,\n",
        "    output_variables=output_variables,\n",
        "    calculate_sensitivities=True,\n",
        ")\n",
        "\n",
        "# ... and then obtain JAX interface function\n",
        "f = jax_solver.get_jaxpr()"
      ],
      "metadata": {
        "id": "rk4RYT2-z6BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The JAX expression (that we named `f` in our example) can be used as any other native JAX expression. This means that it can be included in broader JAX expressions, and can even be JIT compiled (though we only support CPU, not GPU or TPU, compilation at present). The only limitation is that derivatives cannot be taken beyond first-order.\n",
        "\n",
        "Here is the most basic usage example:"
      ],
      "metadata": {
        "id": "Wjp4Fpj402Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all output variables, evaluated over the provided time vector\n",
        "data = f(t_eval, inputs)\n",
        "print(data)"
      ],
      "metadata": {
        "id": "VCKYxXMD0xTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to JAX compatibility, the IDAKLU-Jax interface provides several helper functions. Notably, we provide the facility to isolate a single variables from the JAX expression using the `get_var` helper function, or multiple variables provided as a list by using the `get_vars` helper function."
      ],
      "metadata": {
        "id": "tUZurVD26t4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Isolate a single variables\n",
        "data = jax_solver.get_var(f, \"Terminal voltage [V]\")(t_eval, inputs)\n",
        "print(data)\n",
        "\n",
        "# Isolate two variables from the solver\n",
        "data = jax_solver.get_vars([\n",
        "    \"Terminal voltage [V]\",\n",
        "    \"Discharge capacity [A.h]\",\n",
        "])(t_eval, inputs)"
      ],
      "metadata": {
        "id": "7UnY6goK633s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "As with any JAX expression, we build functional expressions and only evaluate the outer-most expression. In other words, we wrap the expression `f` within an enclosing function `jax_solver.get_var(f, ...)` to form a new functional JAX expression. We evaluate that expression by passing our arguments `(t_eval, inputs)` at the end of the expression (so that they are passed to the highest functional).\n",
        "\n",
        "To compute the Jacobian matrix (the matrix of derivates of output variables with respect to each input parameter), make use of the Jacobian forward derivation `jax.jacfwd` and Jacobian reverse derivation `jax.jacrev` functions.\n",
        "\n",
        "When calling these functions we note that `argnums=1` signifies that we are taking the Jacobian with respect to the second argument (indexing from 0: `inputs`). Since `inputs` is a dictionary of input parameters, the result will also be a dictionary of derivatives with respect to each dictionary key / input parameter. These two methods (`jacfwd` and `jacrev`) will produce the same output, it is simply their derivation that differs."
      ],
      "metadata": {
        "id": "IK32lBj9_rcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the Jacobian matrix (via forward autodiff)\n",
        "out = jax.jacfwd(f, argnums=1)(t_eval, inputs)\n",
        "print(out)\n",
        "\n",
        "# Calculate Jacobian matrix (via backward autodiff)\n",
        "out = jax.jacrev(f, argnums=1)(t_eval, inputs)\n",
        "print(out)"
      ],
      "metadata": {
        "id": "PmPfHSRu8N-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gradient (`grad`) on the other hand must return a scalar value. The function must therefore be called with scalar arguments (including scalar time) and can only be evaluted for one output variable at a time. These restrictions can be overcome through use of the `get_var` function, and the `vmap` function (which provides vector-mapping over time), as demonstrated below."
      ],
      "metadata": {
        "id": "2tC9Bp_g9mOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example evaluation using the `grad` function\n",
        "data = jax.vmap(\n",
        "    jax.grad(\n",
        "        jax_solver.get_var(f,\"Terminal Voltage [V]\"),\n",
        "        argnums=1,  # take derivative with respect to `inputs`\n",
        "    ),\n",
        "    in_axes=(0, None)  # map time over the 0th dimension and do not map inputs\n",
        ")(t_eval, inputs)\n",
        "print(data)"
      ],
      "metadata": {
        "id": "sJjWUIcG9lWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A use-case example\n",
        "\n",
        "As a use-case example, consider a fitting procedure where we want to compare simulation data against some experimental data. We achieve this by computing the sum-of-squared errors between the two. Many fitting procedures will converge more quickly (with fewer iterations) if both the value *and gradient* of the SSE function are provided. By making use of JAX-expressions we can derive these effortlessly.\n",
        "\n",
        "*Note*: We do not need to map over time when calling `value_and_grad` in this example since the `sse` function returns a scalar (despite taking a vector as input)."
      ],
      "metadata": {
        "id": "G0bo1TPL-ZAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate some experimental data using our original parameter settings\n",
        "data = sim[\"Terminal Voltage [V]\"](t_eval)\n",
        "\n",
        "# Sum-of-squared errors\n",
        "def sse(t, inputs):\n",
        "    modelled = jax_solver.get_var(f, \"Terminal voltage [V]\")(t_eval, inputs)\n",
        "    return jnp.sum((modelled - data) ** 2)\n",
        "\n",
        "# Provide some predicted model inputs (these could come from a fitting procedure)\n",
        "inputs_pred = {\n",
        "    \"Current function [A]\": 0.150,\n",
        "    \"Separator porosity\": 0.333,\n",
        "}\n",
        "\n",
        "# Get the value and gradient of the SSE function\n",
        "value, gradient = jax.value_and_grad(sse, argnums=1)(t_eval, inputs_pred)\n",
        "print(f\"{value=}, {gradient=}\")"
      ],
      "metadata": {
        "id": "56NPH9sZ-ZFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of the above expressions can be JIT compiled (onto CPU) by using the `jax.jit` directive. Practically, this provides a wrap-around back to the Python interface of the IDAKLU Solver, so is only provided to afford maximum downstream compatibility (where JIT may be called outside of the user's control). For speed/efficiency reasons it is recommended to avoid the `jax.jit` directive."
      ],
      "metadata": {
        "id": "Nj0ylzso8Yu_"
      }
    }
  ]
}